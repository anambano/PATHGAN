{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "25c7d66cd9316a04e175245738b2e137f8614713"
   },
   "source": [
    "# Path planning using GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "62275ca561cbdb5885225e44c41196be117dffa5"
   },
   "source": [
    "## Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "50a04676ef8767a1788f12c456e120a6e82188d3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm.notebook as tqdm\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import os\n",
    "import time\n",
    "from pylab import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a1f8bd6664dba473f9ab2c773a2c07c4a782167a"
   },
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "89e7394505d86a7ae5a475d3c023551a2a445fce"
   },
   "outputs": [],
   "source": [
    "data_path = \"D:\\ML\\PATHGAN\\input\\dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "129a3712f67bbb8f3a222e21cc33571319b8f63f"
   },
   "source": [
    "### Prining a sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7bbf090dbf03b4c8a3b475ca78a6f687a825ad61"
   },
   "outputs": [],
   "source": [
    "sample_data = os.path.join(data_path, \"00_010.csv\")\n",
    "sample_df = pd.read_csv(sample_data, index_col=None, header=None)\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fb34c6a51823b65d1b877be3279dda73e5b7ecd3"
   },
   "source": [
    "### Visual representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b121c62f3c23a91ce3cceb4abcb43fff49e412c3"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(sample_df.values, interpolation='nearest')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "15c8404399f7c1921d01a31be1d4828ada04d415"
   },
   "source": [
    "Load all the training paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "def loadData(path=data_path):\n",
    "    files = os.listdir(path)\n",
    "    data = []\n",
    "    labels = []\n",
    "    for fn in files:\n",
    "        if int(fn[0:2]) == 0:\n",
    "            ffn = os.path.join(path, fn)\n",
    "            df = pd.read_csv(ffn, index_col=None, header=None)\n",
    "            df[df==2]=0\n",
    "            data.append(df.values)\n",
    "            label = int(fn[0:2])\n",
    "            labels.append(label)\n",
    "    data = np.array(data) \n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "data, labels = loadData()\n",
    "print(\"Loaded: %s paths\" % (len(labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the GAN function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f5d71c308c9c3b15da8244a29b32e0ca2dc0c091"
   },
   "outputs": [],
   "source": [
    "class GAN():\n",
    "    def __init__(self, img_rows=19, img_cols=13, channels=1):\n",
    "        self.img_rows = img_rows\n",
    "        self.img_cols = img_cols\n",
    "        self.channels = channels\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "                                   optimizer=optimizer,\n",
    "                                   metrics=['accuracy'])\n",
    "\n",
    "        # Build and compile the generator\n",
    "        self.generator = self.build_generator()\n",
    "        self.generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "        # The generator takes noise as input and generated imgs\n",
    "        z = Input(shape=(100,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The valid takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator) takes\n",
    "        # noise as input => generates images => determines validity \n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        noise_shape = (100,)\n",
    "\n",
    "        model = Sequential()\n",
    "        \n",
    "        #Convolutional Layer1\n",
    "        model.add(Dense(256, input_shape=noise_shape))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        \n",
    "        #Layer2\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        \n",
    "        #Layer3\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        \n",
    "        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n",
    "        model.add(Reshape(self.img_shape))\n",
    "\n",
    "        #model.summary()\n",
    "\n",
    "        noise = Input(shape=noise_shape)\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "\n",
    "        model = Sequential()\n",
    "        \n",
    "        #Conv. Layer1\n",
    "        model.add(Flatten(input_shape=img_shape))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        \n",
    "        #Layer2\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        \n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        #model.summary()\n",
    "\n",
    "        img = Input(shape=img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, X_train, y_, epochs=1000, batch_size=2):\n",
    "\n",
    "        X_train = 2 * (X_train.astype(np.float32)) - 1\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "        half_batch = int(batch_size / 2)\n",
    "\n",
    "        for epoch in tqdm.trange(epochs, desc='Training'):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random half batch of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "            imgs = X_train[idx]\n",
    "\n",
    "            noise = np.random.normal(0, 1, (half_batch, 100))\n",
    "\n",
    "            # Generate a half batch of new images\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "            # Train the discriminator\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "\n",
    "            # The generator wants the discriminator to label the generated samples as valid (ones)\n",
    "            valid_y = np.array([1] * batch_size)\n",
    "\n",
    "            # Train the generator\n",
    "            g_loss = self.combined.train_on_batch(noise, valid_y)\n",
    "            \n",
    "        \n",
    "    \n",
    "    def save_pgan_model(self):\n",
    "        self.generator.save_weights('D:\\ML\\PATHGAN\\PathGANckpt.ckpt')\n",
    "        self.generator.save('D:\\ML\\PATHGAN\\PathGAN.h5')\n",
    "        #self.generator.save('D:\\ML\\PATHGAN\\PathGANFull')\n",
    "        \n",
    "        \n",
    "    def load_pgan_model(self):\n",
    "        self.generator = tf.keras.models.load_model('D:\\ML\\PATHGAN\\PathGAN.h5')\n",
    "        #self.generator.load_weights('D:\\ML\\PATHGAN\\PathGANckpt.ckpt')\n",
    "        #self.generator = tf.keras.models.load_model('D:\\ML\\PATHGAN\\PathGANFull')\n",
    "        print(\"Loaded the model from file\")\n",
    "        self.generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d261fcf8e9e09d52017c675ebf7040c563b0a454"
   },
   "source": [
    "### Build and Train the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6202a5360aa4200b230c014dd9c711a9e4478147"
   },
   "outputs": [],
   "source": [
    "gan = GAN()\n",
    "start_time = time.time()\n",
    "gan.train(data, labels, epochs=1000, batch_size=8)\n",
    "#gan.save_pgan_model()\n",
    "print(\"total training time: %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6602b29083c13fa830de8eb6b354cd469283bebe"
   },
   "source": [
    "### Load from saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gan.load_pgan_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the generator to generate a random path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8745829b9ed789185c8e7a9fc0824f948aaddc09"
   },
   "outputs": [],
   "source": [
    "#gen_samples_row, gen_samples_col = 1,1\n",
    "#count = gen_samples_row*gen_samples_col\n",
    "count=1\n",
    "noise = np.random.normal(0, 1, (count, 100))\n",
    "\n",
    "# Generate images from noise data\n",
    "gen_imgs = gan.generator.predict(noise)\n",
    "\n",
    "\n",
    "#Rescale image pixels in 0 - 1\n",
    "gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "# Display the generated path in matplotlib\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(gen_imgs[0], cmap=plt.cm.gray)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
